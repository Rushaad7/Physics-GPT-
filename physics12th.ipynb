{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/My Drive/physics-science.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "print(\"Length of characters in physics: \",len(text))\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"thermodynamics\"))\n",
        "print(decode(encode(\"thermodynamics\")))\n",
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "import torch # we use PyTorch: https://pytorch.org\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this\n",
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])\n",
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "block_size = 8\n",
        "train_data[:block_size+1]\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")\n",
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")\n",
        "print(xb) # our input to the transformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(100): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))\n",
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)\n",
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape\n",
        "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n",
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "torch.allclose(xbow, xbow2)\n",
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)\n",
        "# version 4: self-attention!\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape\n",
        "wei[0]\n",
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
        "k.var()\n",
        "q.var()\n",
        "wei.var()\n",
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)\n",
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot\n",
        "class LayerNorm1d: # (used to be BatchNorm1d)\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    xmean = x.mean(1, keepdim=True) # batch mean\n",
        "    xvar = x.var(1, keepdim=True) # batch variance\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = LayerNorm1d(100)\n",
        "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
        "x = module(x)\n",
        "x.shape\n",
        "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs\n",
        "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQMPlG1ds8hx",
        "outputId": "9c708fc3-d073-429a-de45-62ca9478a458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Length of characters in physics:  1057404\n",
            "\t\n",
            "\f\u000e\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c\u001d\u001e\u001f !\"#%&'()+,-./0123456789:;<=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz{|}~ ©­°±µº½Å×åòˆ̂ΔΣΩαβγδεηθλμνπρστφχωϕँआकगतमयलाुृोौ् ‍–‘’“”•…′ℓΩ→⇒∆∑−∙√∝∞∠∫∴∵∼≅≈≠≤≥⊕⊗⊥⋅￼\n",
            "208\n",
            "[100, 88, 85, 98, 93, 95, 84, 105, 94, 81, 93, 89, 83, 99]\n",
            "thermodynamics\n",
            "torch.Size([1057404]) torch.int64\n",
            "tensor([  2,  70,  88,  85,  21,  53,  95,  95,  98,  84,  89,  94,  81, 100,\n",
            "         89,  95,  94,  21,  53,  95,  93,  93,  89, 100, 100,  85,  85,  21,\n",
            "         86,  95,  98,  93,  85,  84,  21,  82, 105,  21,  57,  68,  21,  64,\n",
            "         95,  33,  21,  51,  82,  88, 105,  81,  99,  21,  32,  21,  37,  36,\n",
            "         36,  41,  34,  28,  66,  98,  81,  33,  61,  98,  81,  33,  39,  38,\n",
            "         34,  36,  41,  29,  21,  69,  54,  21,  32,  21,  39,   1,  54,  81,\n",
            "        100,  85,  84,  21,  37,  40,  33,  39,  33,  37,  35,  36,  41,  21,\n",
            "         88,  81,  99,  21,  87,  89, 102,  85,  94,  21,  81,  96,  96,  98,\n",
            "         95, 102,  81,  92,  21, 100,  95,  21,  96,  98,  85,  99,  83,  98,\n",
            "         89,  82,  85,  21, 100,  88,  89,  99,  21, 100,  85, 104, 100,  82,\n",
            "         95,  95,  91,  21,  89,  94,  21,  89, 100,  99,  21,  93,  85,  85,\n",
            "        100,  89,  94,  87,  21,  88,  85,  92,  84,  21,  95,  94,   1,  38,\n",
            "         35,  33,  35,  36,  33,  37,  35,  37,  35,  21,  81,  94,  84,  21,\n",
            "         89, 100,  21,  88,  81,  99,  21,  82,  85,  85,  94,  21,  84,  85,\n",
            "         83,  89,  84,  85,  84,  21, 100,  95,  21,  89,  93,  96,  92,  85,\n",
            "         93,  85,  94, 100,  21,  89, 100,  21,  86,  98,  95,  93,  21,  81,\n",
            "         83,  81,  84,  85,  93,  89,  83,  21, 105,  85,  81,  98,  21,  37,\n",
            "         35,  37,  35,  32,  37,  36,   1,   1,  66,  58,  75,  69,  59,  53,\n",
            "         69,   1,  69, 100,  81,  94,  84,  81,  98,  84,  21,  74,  59,  59,\n",
            "          1,   1,  54,  95, 103,  94,  92,  95,  81,  84,  21,  54,  59,  61,\n",
            "         69,  58,  51,  21,  51,  96,  96,  21,  95,  94,  21, 105,  95, 101,\n",
            "         98,  21,  99,  93,  81,  98, 100,  96,  88,  95,  94,  85,  33,  21,\n",
            "         59,  86,  21, 105,  95, 101,   1,  99,  83,  81,  94,  21, 100,  88,\n",
            "         85,  21,  67,  33,  68,  33,  53,  95,  84,  85,  21,  95,  94,  21,\n",
            "        100,  88,  89,  99,  21,  96,  81,  87,  85,  21,  95,  86,  21, 105,\n",
            "         95, 101,  98,  21, 100,  85, 104, 100,  82,  95,  95,  91,  31,  21,\n",
            "        105,  95, 101,   1, 103,  89,  92,  92,  21,  82,  85,  21,  81,  82,\n",
            "         92,  85,  21, 100,  95,  21,  81,  83,  83,  85,  99,  99,  21,  86,\n",
            "        101,  92,  92,  21, 100,  85, 104, 100,  21,  81,  94,  84,  21, 100,\n",
            "         88,  85,  21,  81, 101,  84,  89,  95,  32, 102,  89,  99, 101,  81,\n",
            "         92,  21,  99, 100, 101,  84, 105,   1,  93,  81, 100,  85,  98,  89,\n",
            "         81,  92,  21,  98,  85,  92,  85, 102,  81,  94, 100,  21, 100,  95,\n",
            "         21,  85,  81,  83,  88,  21,  92,  85,  99,  99,  95,  94,  31,  21,\n",
            "         96,  98,  95, 102,  89,  84,  85,  84,  21,  81,  99,  21, 100,  85,\n",
            "         81,  83,  88,  89,  94,  87,   1,  81,  94,  84,  21,  92,  85,  81,\n",
            "         98,  94,  89,  94,  87,  21,  81,  89,  84,  99,  33,   1,   1,  37,\n",
            "         35,  37,  35,   1,   1,  63,  81,  88,  81,  98,  81,  99,  88, 100,\n",
            "         98,  81,  21,  69, 100,  81, 100,  85,  21,  52, 101,  98,  85,  81,\n",
            "        101,  21,  95,  86,  21,  70,  85, 104, 100,  82,  95,  95,  91,  21,\n",
            "         66,  98,  95,  84, 101,  83, 100,  89,  95,  94,  21,  81,  94,  84,\n",
            "          1,  53, 101,  98,  98,  89,  83, 101,  92, 101,  93,  21,  68,  85,\n",
            "         99,  85,  81,  98,  83,  88,  31,  21,  66, 101,  94,  85,  33,   1,\n",
            "          1,   2,  56,  89,  98,  99, 100,  21,  55,  84,  89, 100,  89,  95,\n",
            "         94,  21,  45,   1,  37,  35,  37,  35,   1,   1, 112,  21,  63,  81,\n",
            "         88,  81,  98,  81,  99,  88, 100,  98,  81,  21,  69, 100,  81, 100,\n",
            "         85,  21,  52, 101,  98,  85,  81, 101,  21,  95,  86,  21,  70,  85,\n",
            "        104, 100,  82,  95,  95,  91,  21,  66,  98,  95,  84, 101,  83, 100,\n",
            "         89,  95,  94,  21,  81,  94,  84,   1,  53, 101,  98,  98,  89,  83,\n",
            "        101,  92, 101,  93,  21,  68,  85,  99,  85,  81,  98,  83,  88,  31,\n",
            "         21,  66, 101,  94,  85,  21,  32,  21,  39,  36,  36,  21,  35,  35,\n",
            "         39,  33,   1,  70,  88,  85,  21,  63,  81,  88,  81,  98,  81,  99,\n",
            "         88, 100,  98,  81,  21,  69, 100,  81, 100,  85,  21,  52, 101,  98,\n",
            "         85,  81, 101,  21,  95,  86,  21,  70,  85, 104, 100,  82,  95,  95,\n",
            "         91,  21,  66,  98,  95,  84, 101,  83, 100,  89,  95,  94,   1,  81,\n",
            "         94,  84,  21,  53, 101,  98,  98,  89,  83, 101,  92, 101,  93,  21,\n",
            "         68,  85,  99,  85,  81,  98,  83,  88,  21,  98,  85,  99,  85,  98,\n",
            "        102,  85,  99,  21,  81,  92,  92,  21,  98,  89,  87,  88, 100,  99,\n",
            "         21,  98,  85,  92,  81, 100,  89,  94,  87,  21, 100,  95,   1, 100,\n",
            "         88,  85,  21,  82,  95,  95,  91,  33,  21,  64,  95,  21,  96,  81,\n",
            "         98, 100,  21,  95,  86,  21, 100,  88,  89,  99,  21,  82,  95,  95,\n",
            "         91,  21,  99,  88,  95, 101,  92,  84,  21,  82,  85,  21,  98,  85,\n",
            "         96,  98,  95,  84, 101,  83,  85,  84,   1, 103,  89, 100,  88,  95,\n",
            "        101, 100,  21, 100,  88,  85,  21, 103,  98,  89, 100, 100,  85,  94,\n",
            "         21,  96,  85,  98,  93,  89,  99,  99,  89,  95,  94,  21,  95,  86,\n",
            "         21, 100,  88,  85,  21,  54,  89,  98,  85,  83, 100,  95,  98,  31,\n",
            "         21,  63,  81,  88,  81,  98,  81,  99,  88, 100,  98,  81,   1,  69,\n",
            "        100,  81, 100,  85,  21,  52, 101,  98,  85,  81, 101,  21,  95,  86,\n",
            "         21,  70,  85, 104, 100,  82,  95,  95,  91,  21,  66,  98,  95,  84,\n",
            "        101,  83, 100,  89,  95,  94,  21,  81,  94,  84,  21,  53, 101,  98,\n",
            "         98,  89,  83, 101,  92, 101,  93,   1,  68,  85,  99,  85,  81,  98,\n",
            "         83,  88,  31,  21, 163,  52,  81,  92,  82,  88,  81,  98,  81, 100,\n",
            "         89, 164,  31,  21,  69,  85])\n",
            "\fThe Coordination Committee formed by GR No. Abhyas - 2116/(Pra.Kra.43/16) SD - 4\n",
            "Dated 25.4.2016 has given approval to prescribe this textbook in its meeting held on\n",
            "30.01.2020 and it has been decided to implement it from academic year 2020-21\n",
            "\n",
            "PHYSICS\n",
            "Standard XII\n",
            "\n",
            "Download DIKSHA App on your smartphone. If you\n",
            "scan the Q.R.Code on this page of your textbook, you\n",
            "will be able to access full text and the audio-visual study\n",
            "material relevant to each lesson, provided as teaching\n",
            "and learning aids.\n",
            "\n",
            "2020\n",
            "\n",
            "Maharashtra State Bureau of Textbook Production and\n",
            "Curriculum Research, Pune.\n",
            "\n",
            "\fFirst Edition :\n",
            "2020\n",
            "\n",
            "© Maharashtra State Bureau of Textbook Production and\n",
            "Curriculum Research, Pune - 411 004.\n",
            "The Maharashtra State Bureau of Textbook Production\n",
            "and Curriculum Research reserves all rights relating to\n",
            "the book. No part of this book should be reproduced\n",
            "without the written permission of the Director, Maharashtra\n",
            "State Bureau of Textbook Production and Curriculum\n",
            "Research, ‘Balbharati’, Se\n",
            "when input is tensor([2]) the target: 70\n",
            "when input is tensor([ 2, 70]) the target: 88\n",
            "when input is tensor([ 2, 70, 88]) the target: 85\n",
            "when input is tensor([ 2, 70, 88, 85]) the target: 21\n",
            "when input is tensor([ 2, 70, 88, 85, 21]) the target: 53\n",
            "when input is tensor([ 2, 70, 88, 85, 21, 53]) the target: 95\n",
            "when input is tensor([ 2, 70, 88, 85, 21, 53, 95]) the target: 95\n",
            "when input is tensor([ 2, 70, 88, 85, 21, 53, 95, 95]) the target: 98\n",
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 88,  21,  84,  81,  98,  91,  21,  96],\n",
            "        [ 21,  86,  89,  85,  92,  84,  21,  84],\n",
            "        [ 88,  85,  98,  85,  86,  95,  98,  85],\n",
            "        [ 21,  86,  98,  95,  93,  21, 100,  88]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 21,  84,  81,  98,  91,  21,  96,  95],\n",
            "        [ 86,  89,  85,  92,  84,  21,  84, 101],\n",
            "        [ 85,  98,  85,  86,  95,  98,  85,  31],\n",
            "        [ 86,  98,  95,  93,  21, 100,  88,  85]])\n",
            "----\n",
            "when input is [88] the target: 21\n",
            "when input is [88, 21] the target: 84\n",
            "when input is [88, 21, 84] the target: 81\n",
            "when input is [88, 21, 84, 81] the target: 98\n",
            "when input is [88, 21, 84, 81, 98] the target: 91\n",
            "when input is [88, 21, 84, 81, 98, 91] the target: 21\n",
            "when input is [88, 21, 84, 81, 98, 91, 21] the target: 96\n",
            "when input is [88, 21, 84, 81, 98, 91, 21, 96] the target: 95\n",
            "when input is [21] the target: 86\n",
            "when input is [21, 86] the target: 89\n",
            "when input is [21, 86, 89] the target: 85\n",
            "when input is [21, 86, 89, 85] the target: 92\n",
            "when input is [21, 86, 89, 85, 92] the target: 84\n",
            "when input is [21, 86, 89, 85, 92, 84] the target: 21\n",
            "when input is [21, 86, 89, 85, 92, 84, 21] the target: 84\n",
            "when input is [21, 86, 89, 85, 92, 84, 21, 84] the target: 101\n",
            "when input is [88] the target: 85\n",
            "when input is [88, 85] the target: 98\n",
            "when input is [88, 85, 98] the target: 85\n",
            "when input is [88, 85, 98, 85] the target: 86\n",
            "when input is [88, 85, 98, 85, 86] the target: 95\n",
            "when input is [88, 85, 98, 85, 86, 95] the target: 98\n",
            "when input is [88, 85, 98, 85, 86, 95, 98] the target: 85\n",
            "when input is [88, 85, 98, 85, 86, 95, 98, 85] the target: 31\n",
            "when input is [21] the target: 86\n",
            "when input is [21, 86] the target: 98\n",
            "when input is [21, 86, 98] the target: 95\n",
            "when input is [21, 86, 98, 95] the target: 93\n",
            "when input is [21, 86, 98, 95, 93] the target: 21\n",
            "when input is [21, 86, 98, 95, 93, 21] the target: 100\n",
            "when input is [21, 86, 98, 95, 93, 21, 100] the target: 88\n",
            "when input is [21, 86, 98, 95, 93, 21, 100, 88] the target: 85\n",
            "tensor([[ 88,  21,  84,  81,  98,  91,  21,  96],\n",
            "        [ 21,  86,  89,  85,  92,  84,  21,  84],\n",
            "        [ 88,  85,  98,  85,  86,  95,  98,  85],\n",
            "        [ 21,  86,  98,  95,  93,  21, 100,  88]])\n",
            "torch.Size([32, 208])\n",
            "tensor(5.7169, grad_fn=<NllLossBackward0>)\n",
            "\tDTZm‘ त∴θ∝u\f#3~9“∵→yθ′यM′wh`-\n",
            "ϕϕHv&Ω}no⋅Lò\u001aोाηxθ′tˆW∙uयG/6±µ\u001e\u001d\u001fσℓ–)ò√πम∴ZbआωगòF‘K\u001eo\u000fp\u0010\u0014τ\u0010य‘}±TkM\n",
            "5.771679401397705\n",
            "\tDDc'ँ:R~(e\u001f1.νε\u0014δ{{vDc`∠LDò%m−∫∆\u0018kआ∞/3HR±σ⇒½≅iϕ+b\u0018∙2Qafत}ò￼!z∴मRf+u f0‍G)̂axग\u0018\u001eγK∠\u000etdIµ~±̂}α∠l∆Dε\u001clδλ⇒0\u0011̂∆d\u001e≅±l(,λ∫=½G“\f\u0010Å\u0011Σχℓro8̂η_s:sε\fdθ∝\n",
            "=⋅φ≥t(गc\u001bN!θ\u0015)oΣ∫\u0016σ∴η:~\u0012\fò\tाNxलIf?L⊗{ ρ￼य\u0011T≅bSx‍πH(\u0018u\t,2oग￼'ँo7A\u0016S|U7%r\u0017कn%∠1\u001d̂±⊥∠Nβ\u0015⋅γ”⊕\t≤k\u0018…≈’.#⋅p#SURi×5∑ˆγ…EL\u000f\"2,Zbò%”k\u0017gμआ°→ँ⊗‍\u000fdnη\u0014\u001a\"−Tρn\f\n",
            "\t?μNEΔδ√πφ_ाº”⊗≈JतN<_½गUσ∴1≥uOमO©मò\n",
            "ν=−⇒⇒∞Ω−•βuΩ\u0019म∞\u0010D \u0011°∝Cβ\t\u001e≤\u0018{,\u001dMm­r \u001c′aρ￼,\u0011ρˆ1`pg∫⊥x3 k\f l\"\u001de\n",
            "©½p‍\u0010πLX￼σu∵BL⊗93Y−v⊕्तp\u00131≤×–1 ×+Rò∫\u001bpk\u001eG–0q oगρÅu\u001c\u001f≤r\u00142Q-∴!\u001aमP≠K⊕ˆ_￼“⋅•u°्lँग\u0014ρ1bAâ′­XP≥\n",
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-9.5367e-09), tensor(1.0000))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BnybG9l8BJSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b6be9f-d3df-4f56-9022-2f31ca5f0c5d",
        "id": "7PkBXAS9CxJV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/physics-science.txt', 'r') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "qxoMDQwes8kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of characters in physics: \",len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLsxDmPZs8ov",
        "outputId": "5d8841a7-1729-4a07-a88f-ed694f12c580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of characters in physics:  1057404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaCbemMns8re",
        "outputId": "a392c523-ec86-4835-dd6d-4acc850b7bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\n",
            "\f\u000e\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c\u001d\u001e\u001f !\"#%&'()+,-./0123456789:;<=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz{|}~ ©­°±µº½Å×åòˆ̂ΔΣΩαβγδεηθλμνπρστφχωϕँआकगतमयलाुृोौ् ‍–‘’“”•…′ℓΩ→⇒∆∑−∙√∝∞∠∫∴∵∼≅≈≠≤≥⊕⊗⊥⋅￼\n",
            "208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"thermodynamics\"))\n",
        "print(decode(encode(\"thermodynamics\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvRd0BJys8uO",
        "outputId": "bc35374e-1167-4939-e03f-75462e4495ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100, 88, 85, 98, 93, 95, 84, 105, 94, 81, 93, 89, 83, 99]\n",
            "thermodynamics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "import torch # we use PyTorch: https://pytorch.org\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYO9MWAps8wm",
        "outputId": "9764ed0f-afca-4251-8072-830e97877943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1057404]) torch.int64\n",
            "tensor([  2,  70,  88,  85,  21,  53,  95,  95,  98,  84,  89,  94,  81, 100,\n",
            "         89,  95,  94,  21,  53,  95,  93,  93,  89, 100, 100,  85,  85,  21,\n",
            "         86,  95,  98,  93,  85,  84,  21,  82, 105,  21,  57,  68,  21,  64,\n",
            "         95,  33,  21,  51,  82,  88, 105,  81,  99,  21,  32,  21,  37,  36,\n",
            "         36,  41,  34,  28,  66,  98,  81,  33,  61,  98,  81,  33,  39,  38,\n",
            "         34,  36,  41,  29,  21,  69,  54,  21,  32,  21,  39,   1,  54,  81,\n",
            "        100,  85,  84,  21,  37,  40,  33,  39,  33,  37,  35,  36,  41,  21,\n",
            "         88,  81,  99,  21,  87,  89, 102,  85,  94,  21,  81,  96,  96,  98,\n",
            "         95, 102,  81,  92,  21, 100,  95,  21,  96,  98,  85,  99,  83,  98,\n",
            "         89,  82,  85,  21, 100,  88,  89,  99,  21, 100,  85, 104, 100,  82,\n",
            "         95,  95,  91,  21,  89,  94,  21,  89, 100,  99,  21,  93,  85,  85,\n",
            "        100,  89,  94,  87,  21,  88,  85,  92,  84,  21,  95,  94,   1,  38,\n",
            "         35,  33,  35,  36,  33,  37,  35,  37,  35,  21,  81,  94,  84,  21,\n",
            "         89, 100,  21,  88,  81,  99,  21,  82,  85,  85,  94,  21,  84,  85,\n",
            "         83,  89,  84,  85,  84,  21, 100,  95,  21,  89,  93,  96,  92,  85,\n",
            "         93,  85,  94, 100,  21,  89, 100,  21,  86,  98,  95,  93,  21,  81,\n",
            "         83,  81,  84,  85,  93,  89,  83,  21, 105,  85,  81,  98,  21,  37,\n",
            "         35,  37,  35,  32,  37,  36,   1,   1,  66,  58,  75,  69,  59,  53,\n",
            "         69,   1,  69, 100,  81,  94,  84,  81,  98,  84,  21,  74,  59,  59,\n",
            "          1,   1,  54,  95, 103,  94,  92,  95,  81,  84,  21,  54,  59,  61,\n",
            "         69,  58,  51,  21,  51,  96,  96,  21,  95,  94,  21, 105,  95, 101,\n",
            "         98,  21,  99,  93,  81,  98, 100,  96,  88,  95,  94,  85,  33,  21,\n",
            "         59,  86,  21, 105,  95, 101,   1,  99,  83,  81,  94,  21, 100,  88,\n",
            "         85,  21,  67,  33,  68,  33,  53,  95,  84,  85,  21,  95,  94,  21,\n",
            "        100,  88,  89,  99,  21,  96,  81,  87,  85,  21,  95,  86,  21, 105,\n",
            "         95, 101,  98,  21, 100,  85, 104, 100,  82,  95,  95,  91,  31,  21,\n",
            "        105,  95, 101,   1, 103,  89,  92,  92,  21,  82,  85,  21,  81,  82,\n",
            "         92,  85,  21, 100,  95,  21,  81,  83,  83,  85,  99,  99,  21,  86,\n",
            "        101,  92,  92,  21, 100,  85, 104, 100,  21,  81,  94,  84,  21, 100,\n",
            "         88,  85,  21,  81, 101,  84,  89,  95,  32, 102,  89,  99, 101,  81,\n",
            "         92,  21,  99, 100, 101,  84, 105,   1,  93,  81, 100,  85,  98,  89,\n",
            "         81,  92,  21,  98,  85,  92,  85, 102,  81,  94, 100,  21, 100,  95,\n",
            "         21,  85,  81,  83,  88,  21,  92,  85,  99,  99,  95,  94,  31,  21,\n",
            "         96,  98,  95, 102,  89,  84,  85,  84,  21,  81,  99,  21, 100,  85,\n",
            "         81,  83,  88,  89,  94,  87,   1,  81,  94,  84,  21,  92,  85,  81,\n",
            "         98,  94,  89,  94,  87,  21,  81,  89,  84,  99,  33,   1,   1,  37,\n",
            "         35,  37,  35,   1,   1,  63,  81,  88,  81,  98,  81,  99,  88, 100,\n",
            "         98,  81,  21,  69, 100,  81, 100,  85,  21,  52, 101,  98,  85,  81,\n",
            "        101,  21,  95,  86,  21,  70,  85, 104, 100,  82,  95,  95,  91,  21,\n",
            "         66,  98,  95,  84, 101,  83, 100,  89,  95,  94,  21,  81,  94,  84,\n",
            "          1,  53, 101,  98,  98,  89,  83, 101,  92, 101,  93,  21,  68,  85,\n",
            "         99,  85,  81,  98,  83,  88,  31,  21,  66, 101,  94,  85,  33,   1,\n",
            "          1,   2,  56,  89,  98,  99, 100,  21,  55,  84,  89, 100,  89,  95,\n",
            "         94,  21,  45,   1,  37,  35,  37,  35,   1,   1, 112,  21,  63,  81,\n",
            "         88,  81,  98,  81,  99,  88, 100,  98,  81,  21,  69, 100,  81, 100,\n",
            "         85,  21,  52, 101,  98,  85,  81, 101,  21,  95,  86,  21,  70,  85,\n",
            "        104, 100,  82,  95,  95,  91,  21,  66,  98,  95,  84, 101,  83, 100,\n",
            "         89,  95,  94,  21,  81,  94,  84,   1,  53, 101,  98,  98,  89,  83,\n",
            "        101,  92, 101,  93,  21,  68,  85,  99,  85,  81,  98,  83,  88,  31,\n",
            "         21,  66, 101,  94,  85,  21,  32,  21,  39,  36,  36,  21,  35,  35,\n",
            "         39,  33,   1,  70,  88,  85,  21,  63,  81,  88,  81,  98,  81,  99,\n",
            "         88, 100,  98,  81,  21,  69, 100,  81, 100,  85,  21,  52, 101,  98,\n",
            "         85,  81, 101,  21,  95,  86,  21,  70,  85, 104, 100,  82,  95,  95,\n",
            "         91,  21,  66,  98,  95,  84, 101,  83, 100,  89,  95,  94,   1,  81,\n",
            "         94,  84,  21,  53, 101,  98,  98,  89,  83, 101,  92, 101,  93,  21,\n",
            "         68,  85,  99,  85,  81,  98,  83,  88,  21,  98,  85,  99,  85,  98,\n",
            "        102,  85,  99,  21,  81,  92,  92,  21,  98,  89,  87,  88, 100,  99,\n",
            "         21,  98,  85,  92,  81, 100,  89,  94,  87,  21, 100,  95,   1, 100,\n",
            "         88,  85,  21,  82,  95,  95,  91,  33,  21,  64,  95,  21,  96,  81,\n",
            "         98, 100,  21,  95,  86,  21, 100,  88,  89,  99,  21,  82,  95,  95,\n",
            "         91,  21,  99,  88,  95, 101,  92,  84,  21,  82,  85,  21,  98,  85,\n",
            "         96,  98,  95,  84, 101,  83,  85,  84,   1, 103,  89, 100,  88,  95,\n",
            "        101, 100,  21, 100,  88,  85,  21, 103,  98,  89, 100, 100,  85,  94,\n",
            "         21,  96,  85,  98,  93,  89,  99,  99,  89,  95,  94,  21,  95,  86,\n",
            "         21, 100,  88,  85,  21,  54,  89,  98,  85,  83, 100,  95,  98,  31,\n",
            "         21,  63,  81,  88,  81,  98,  81,  99,  88, 100,  98,  81,   1,  69,\n",
            "        100,  81, 100,  85,  21,  52, 101,  98,  85,  81, 101,  21,  95,  86,\n",
            "         21,  70,  85, 104, 100,  82,  95,  95,  91,  21,  66,  98,  95,  84,\n",
            "        101,  83, 100,  89,  95,  94,  21,  81,  94,  84,  21,  53, 101,  98,\n",
            "         98,  89,  83, 101,  92, 101,  93,   1,  68,  85,  99,  85,  81,  98,\n",
            "         83,  88,  31,  21, 163,  52,  81,  92,  82,  88,  81,  98,  81, 100,\n",
            "         89, 164,  31,  21,  69,  85])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1CfngH9Aj3Q",
        "outputId": "f73d4bb1-0dc8-4138-aeaf-535a9bf2861a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\fThe Coordination Committee formed by GR No. Abhyas - 2116/(Pra.Kra.43/16) SD - 4\n",
            "Dated 25.4.2016 has given approval to prescribe this textbook in its meeting held on\n",
            "30.01.2020 and it has been decided to implement it from academic year 2020-21\n",
            "\n",
            "PHYSICS\n",
            "Standard XII\n",
            "\n",
            "Download DIKSHA App on your smartphone. If you\n",
            "scan the Q.R.Code on this page of your textbook, you\n",
            "will be able to access full text and the audio-visual study\n",
            "material relevant to each lesson, provided as teaching\n",
            "and learning aids.\n",
            "\n",
            "2020\n",
            "\n",
            "Maharashtra State Bureau of Textbook Production and\n",
            "Curriculum Research, Pune.\n",
            "\n",
            "\fFirst Edition :\n",
            "2020\n",
            "\n",
            "© Maharashtra State Bureau of Textbook Production and\n",
            "Curriculum Research, Pune - 411 004.\n",
            "The Maharashtra State Bureau of Textbook Production\n",
            "and Curriculum Research reserves all rights relating to\n",
            "the book. No part of this book should be reproduced\n",
            "without the written permission of the Director, Maharashtra\n",
            "State Bureau of Textbook Production and Curriculum\n",
            "Research, ‘Balbharati’, Se\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "uhbrBqkxs8yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ32wf0fs80_",
        "outputId": "7df00997-35d6-410c-8121-7056bc6bc47e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, 70, 88, 85, 21, 53, 95, 95, 98])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfIRg62Ns83o",
        "outputId": "a71e4eb2-6f90-410a-d9a9-b3fd257930f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([2]) the target: 70\n",
            "when input is tensor([ 2, 70]) the target: 88\n",
            "when input is tensor([ 2, 70, 88]) the target: 85\n",
            "when input is tensor([ 2, 70, 88, 85]) the target: 21\n",
            "when input is tensor([ 2, 70, 88, 85, 21]) the target: 53\n",
            "when input is tensor([ 2, 70, 88, 85, 21, 53]) the target: 95\n",
            "when input is tensor([ 2, 70, 88, 85, 21, 53, 95]) the target: 95\n",
            "when input is tensor([ 2, 70, 88, 85, 21, 53, 95, 95]) the target: 98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gtP1LBn6xCb",
        "outputId": "a7b873f4-f47d-4b3a-d066-fb0919c4ac72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 88,  21,  84,  81,  98,  91,  21,  96],\n",
            "        [ 21,  86,  89,  85,  92,  84,  21,  84],\n",
            "        [ 88,  85,  98,  85,  86,  95,  98,  85],\n",
            "        [ 21,  86,  98,  95,  93,  21, 100,  88]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 21,  84,  81,  98,  91,  21,  96,  95],\n",
            "        [ 86,  89,  85,  92,  84,  21,  84, 101],\n",
            "        [ 85,  98,  85,  86,  95,  98,  85,  31],\n",
            "        [ 86,  98,  95,  93,  21, 100,  88,  85]])\n",
            "----\n",
            "when input is [88] the target: 21\n",
            "when input is [88, 21] the target: 84\n",
            "when input is [88, 21, 84] the target: 81\n",
            "when input is [88, 21, 84, 81] the target: 98\n",
            "when input is [88, 21, 84, 81, 98] the target: 91\n",
            "when input is [88, 21, 84, 81, 98, 91] the target: 21\n",
            "when input is [88, 21, 84, 81, 98, 91, 21] the target: 96\n",
            "when input is [88, 21, 84, 81, 98, 91, 21, 96] the target: 95\n",
            "when input is [21] the target: 86\n",
            "when input is [21, 86] the target: 89\n",
            "when input is [21, 86, 89] the target: 85\n",
            "when input is [21, 86, 89, 85] the target: 92\n",
            "when input is [21, 86, 89, 85, 92] the target: 84\n",
            "when input is [21, 86, 89, 85, 92, 84] the target: 21\n",
            "when input is [21, 86, 89, 85, 92, 84, 21] the target: 84\n",
            "when input is [21, 86, 89, 85, 92, 84, 21, 84] the target: 101\n",
            "when input is [88] the target: 85\n",
            "when input is [88, 85] the target: 98\n",
            "when input is [88, 85, 98] the target: 85\n",
            "when input is [88, 85, 98, 85] the target: 86\n",
            "when input is [88, 85, 98, 85, 86] the target: 95\n",
            "when input is [88, 85, 98, 85, 86, 95] the target: 98\n",
            "when input is [88, 85, 98, 85, 86, 95, 98] the target: 85\n",
            "when input is [88, 85, 98, 85, 86, 95, 98, 85] the target: 31\n",
            "when input is [21] the target: 86\n",
            "when input is [21, 86] the target: 98\n",
            "when input is [21, 86, 98] the target: 95\n",
            "when input is [21, 86, 98, 95] the target: 93\n",
            "when input is [21, 86, 98, 95, 93] the target: 21\n",
            "when input is [21, 86, 98, 95, 93, 21] the target: 100\n",
            "when input is [21, 86, 98, 95, 93, 21, 100] the target: 88\n",
            "when input is [21, 86, 98, 95, 93, 21, 100, 88] the target: 85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb) # our input to the transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DURR6_qa6xFV",
        "outputId": "a7539ca6-3f59-4774-d25a-b6982e8f43d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 88,  21,  84,  81,  98,  91,  21,  96],\n",
            "        [ 21,  86,  89,  85,  92,  84,  21,  84],\n",
            "        [ 88,  85,  98,  85,  86,  95,  98,  85],\n",
            "        [ 21,  86,  98,  95,  93,  21, 100,  88]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_DPwNJr6xH_",
        "outputId": "0b09e537-e1b0-471b-b76d-f255f36d5729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 208])\n",
            "tensor(5.7169, grad_fn=<NllLossBackward0>)\n",
            "\tDTZm‘ त∴θ∝u\f#3~9“∵→yθ′यM′wh`-\n",
            "ϕϕHv&Ω}no⋅Lò\u001aोाηxθ′tˆW∙uयG/6±µ\u001e\u001d\u001fσℓ–)ò√πम∴ZbआωगòF‘K\u001eo\u000fp\u0010\u0014τ\u0010य‘}±TkM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "Lmb6jzXw7kTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(100): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b51UWGfh7kV-",
        "outputId": "641c5183-5309-4079-abd3-ce5ce3e2ec6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.771679401397705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul__xA0Y7kYh",
        "outputId": "1be4aafb-e27c-4380-f03b-6eb3ef1633e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tDDc'ँ:R~(e\u001f1.νε\u0014δ{{vDc`∠LDò%m−∫∆\u0018kआ∞/3HR±σ⇒½≅iϕ+b\u0018∙2Qafत}ò￼!z∴मRf+u f0‍G)̂axग\u0018\u001eγK∠\u000etdIµ~±̂}α∠l∆Dε\u001clδλ⇒0\u0011̂∆d\u001e≅±l(,λ∫=½G“\f\u0010Å\u0011Σχℓro8̂η_s:sε\fdθ∝\n",
            "=⋅φ≥t(गc\u001bN!θ\u0015)oΣ∫\u0016σ∴η:~\u0012\fò\tाNxलIf?L⊗{ ρ￼य\u0011T≅bSx‍πH(\u0018u\t,2oग￼'ँo7A\u0016S|U7%r\u0017कn%∠1\u001d̂±⊥∠Nβ\u0015⋅γ”⊕\t≤k\u0018…≈’.#⋅p#SURi×5∑ˆγ…EL\u000f\"2,Zbò%”k\u0017gμआ°→ँ⊗‍\u000fdnη\u0014\u001a\"−Tρn\f\n",
            "\t?μNEΔδ√πφ_ाº”⊗≈JतN<_½गUσ∴1≥uOमO©मò\n",
            "ν=−⇒⇒∞Ω−•βuΩ\u0019म∞\u0010D \u0011°∝Cβ\t\u001e≤\u0018{,\u001dMm­r \u001c′aρ￼,\u0011ρˆ1`pg∫⊥x3 k\f l\"\u001de\n",
            "©½p‍\u0010πLX￼σu∵BL⊗93Y−v⊕्तp\u00131≤×–1 ×+Rò∫\u001bpk\u001eG–0q oगρÅu\u001c\u001f≤r\u00142Q-∴!\u001aमP≠K⊕ˆ_￼“⋅•u°्lँग\u0014ρ1bAâ′­XP≥\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0IB5USW7ka9",
        "outputId": "3abdcf0c-2a21-46a0-cbcc-7132a8fa7bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM13M5bP7kdb",
        "outputId": "5c354254-b14f-419a-94c7-b4f0fe5f9f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)"
      ],
      "metadata": {
        "id": "CPKi_H7K_SKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DaF2Hlb_SNu",
        "outputId": "10e68888-57fb-44d8-999a-8f63f2ccbea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuj6EeuK_SQE",
        "outputId": "ee605e1f-4b42-4d73-ee61-afc381ae8d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention!\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXE3UNDL_SSo",
        "outputId": "88161dc0-285a-4da6-c303-6aa759350b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ9AzIgQ_SUc",
        "outputId": "b50e140d-7162-48bb-a0a3-ae81c698a7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
              "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
              "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
      ],
      "metadata": {
        "id": "H3QI0FrP_SXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3AOwzLVArlW",
        "outputId": "0547493d-25ac-4858-a8e4-eedffc7a5645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0449)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHzrZI2KAroT",
        "outputId": "197facc3-0b87-4705-c707-63e00bf9cc46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0700)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GD6JYxqArq4",
        "outputId": "dedcdc66-77b9-44a5-ee65-f6eb89cd47ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0918)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI7FthQCArtT",
        "outputId": "b420b605-c2c8-4b67-8e98-e8592beae258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhbZbFXjArwE",
        "outputId": "4ebe8abf-aa51-4ca6-f3fe-5e360c80597d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm1d: # (used to be BatchNorm1d)\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    xmean = x.mean(1, keepdim=True) # batch mean\n",
        "    xvar = x.var(1, keepdim=True) # batch variance\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = LayerNorm1d(100)\n",
        "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
        "x = module(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNJnSKxEAryh",
        "outputId": "612c57d1-7c39-4b34-c62a-abd64a1b0b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb5YdTOKBJHq",
        "outputId": "fbd7a533-18ed-4923-b535-f10b39600b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1469), tensor(0.8803))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36SZ0zYhBJK_",
        "outputId": "e29a110f-9365-40c2-b305-3327ec54a5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-9.5367e-09), tensor(1.0000))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oAZSEW92BJYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JMfM3ZLcAr1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "heoK_Vv-Ar3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8DCmcwVe6xL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TUukPkjz6xPF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}